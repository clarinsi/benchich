{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=7\n"
     ]
    }
   ],
   "source": [
    "# Define the gpu on the gpu machine\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the dataset that is being evaluated, extract a list of true labels and a list of unique labels\n",
    "\n",
    "def extract_true_label(dataset, dataset_dict):\n",
    "    \"\"\"The function takes the dataset name and dataset dictionary and returns the list of true labels from the test split.\"\"\"\n",
    "    # Load the json file\n",
    "    with open(dataset_dict[dataset], \"r\") as file:\n",
    "        json_dict = json.load(file)\n",
    "\n",
    "    # Open the test dictionary as DataFrame\n",
    "    test_df = pd.DataFrame(json_dict[\"test\"])\n",
    "\n",
    "    # Extract a list of unique labels\n",
    "    labels = list(test_df.labels.unique())\n",
    "\n",
    "    # Extract label list\n",
    "    y_true = test_df.labels.to_list()\n",
    "\n",
    "    return [y_true, labels]\n",
    "\n",
    "#Calculate the scores\n",
    "def testing(true, pred, labels):\n",
    "    \"\"\"\n",
    "    This function takes the list of true labels and list of predictions and evaluates the model based on comparing them.\n",
    "    It calculates micro and macro F1 scores.\n",
    "    \n",
    "    Args:\n",
    "    - y_true: list of true labels\n",
    "    - y_pred: list of predicted labels\n",
    "    - show_matrix: defaults to False - whether the confusion matrix is printed\n",
    "\n",
    "    The function returns a dictionary with accuracy, micro and macro F1.\n",
    "    \"\"\"\n",
    "    y_true = true\n",
    "    y_pred = pred\n",
    "    LABELS = labels\n",
    "\n",
    "    # Calculate the scores\n",
    "    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n",
    "    micro = f1_score(y_true, y_pred, labels=LABELS,  average=\"micro\")\n",
    "    print(f\"Macro f1: {macro:0.3}, Micro f1: {micro:0.3}\")\n",
    "    \n",
    "    return {\"Micro F1\":micro, \"Macro F1\": macro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated datasets: ['hr500k.json', 'reldi-normtagner-hr.json', 'reldi-normtagner-sr.json', 'set.sr.plus.json']\n"
     ]
    }
   ],
   "source": [
    "# Get all the datasets in the data/datasets directory\n",
    "dataset_path = \"data/datasets/\"\n",
    "\n",
    "datasets = os.listdir(\"data/datasets/\")\n",
    "\n",
    "# Add the path to the datasets\n",
    "dataset_paths = [dataset_path + x for x in datasets]\n",
    "\n",
    "dataset_dict = {x[0]:x[1] for x in list(zip(datasets, dataset_paths))}\n",
    "\n",
    "print(\"Evaluated datasets: {}\".format(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['csebert', 'xlm-r-base', 'xlm-r-large', 'bertic', 'xlm-r-bertic', 'xlm-r-slobertic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the submission to be evaluated\n",
    "path = \"/home/tajak/NER-recognition/benchich/ner/systems/hugging-face-models/submissions\"\n",
    "\n",
    "with open(\"{}/submission-{}-{}.json\".format(path,model, dataset), \"r\") as sub_file:\n",
    "    results = json.load(sub_file)\n",
    "\n",
    "# Extract predictions\n",
    "args = results[\"args\"]\n",
    "\n",
    "epochs = results[\"args\"][\"num_train_epochs\"]\n",
    "lr = results[\"args\"][\"learning_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'set.sr.plus.json'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = results[\"predictions\"][0][\"test\"]\n",
    "dataset = dataset_name.split(\" \")[0]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4e-05"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: csebert on hr500k.json\n",
      "Macro f1: 0.627, Micro f1: 0.959\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: csebert on reldi-normtagner-hr.json\n",
      "Macro f1: 0.517, Micro f1: 0.956\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: csebert on reldi-normtagner-sr.json\n",
      "Macro f1: 0.512, Micro f1: 0.973\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: csebert on set.sr.plus.json\n",
      "Macro f1: 0.612, Micro f1: 0.953\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-base on hr500k.json\n",
      "Macro f1: 0.568, Micro f1: 0.955\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-base on reldi-normtagner-hr.json\n",
      "Macro f1: 0.404, Micro f1: 0.956\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-base on reldi-normtagner-sr.json\n",
      "Macro f1: 0.491, Micro f1: 0.972\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-base on set.sr.plus.json\n",
      "Macro f1: 0.604, Micro f1: 0.953\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-large on hr500k.json\n",
      "Macro f1: 0.0957, Micro f1: 0.917\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-large on reldi-normtagner-hr.json\n",
      "Macro f1: 0.0957, Micro f1: 0.918\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-large on reldi-normtagner-sr.json\n",
      "Macro f1: 0.165, Micro f1: 0.963\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-large on set.sr.plus.json\n",
      "Macro f1: 0.597, Micro f1: 0.952\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: bertic on hr500k.json\n",
      "Macro f1: 0.596, Micro f1: 0.957\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: bertic on reldi-normtagner-hr.json\n",
      "Macro f1: 0.495, Micro f1: 0.961\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: bertic on reldi-normtagner-sr.json\n",
      "Macro f1: 0.518, Micro f1: 0.976\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: bertic on set.sr.plus.json\n",
      "Macro f1: 0.618, Micro f1: 0.954\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-bertic on hr500k.json\n",
      "Macro f1: 0.0957, Micro f1: 0.917\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-bertic on reldi-normtagner-hr.json\n",
      "Macro f1: 0.0957, Micro f1: 0.918\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-bertic on reldi-normtagner-sr.json\n",
      "Macro f1: 0.512, Micro f1: 0.975\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-bertic on set.sr.plus.json\n",
      "Macro f1: 0.59, Micro f1: 0.953\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-slobertic on hr500k.json\n",
      "Macro f1: 0.158, Micro f1: 0.922\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-slobertic on reldi-normtagner-hr.json\n",
      "Macro f1: 0.0957, Micro f1: 0.918\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-slobertic on reldi-normtagner-sr.json\n",
      "Macro f1: 0.0974, Micro f1: 0.949\n",
      "\n",
      "----------------------\n",
      "\n",
      "Evaluation: xlm-r-slobertic on set.sr.plus.json\n",
      "Macro f1: 0.0937, Micro f1: 0.881\n",
      "\n",
      "----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "for model in model_list:\n",
    "    for dataset in datasets:\n",
    "        test_file = extract_true_label(dataset, dataset_dict)\n",
    "        y_true = test_file[0]\n",
    "        labels = test_file[1]\n",
    "\n",
    "        # Open the submission to be evaluated\n",
    "        path = \"/home/tajak/NER-recognition/benchich/ner/systems/hugging-face-models/submissions\"\n",
    "\n",
    "        with open(\"{}/submission-{}-{}.json\".format(path,model, dataset), \"r\") as sub_file:\n",
    "            results = json.load(sub_file)\n",
    "\n",
    "        # Extract information on arguments\n",
    "        epochs = results[\"args\"][\"num_train_epochs\"]\n",
    "        lr = results[\"args\"][\"learning_rate\"]\n",
    "\n",
    "        # Extract predictions\n",
    "        y_pred = results[\"predictions\"][0][\"predictions\"]\n",
    "\n",
    "        print(\"Evaluation: {} on {}\".format(model, dataset))\n",
    "\n",
    "        current_scores = testing(y_true, y_pred, labels)\n",
    "\n",
    "        current_res_dict = {\"Model\": model, \"Test Dataset\": dataset, \"Macro F1\": current_scores[\"Macro F1\"], \"Micro F1\": current_scores[\"Micro F1\"], \"Epochs\": epochs, \"Learning Rate\": lr}\n",
    "\n",
    "        result_list.append(current_res_dict)\n",
    "\n",
    "        print(\"\\n----------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe\n",
    "\n",
    "result_df = pd.DataFrame(result_list)\n",
    "\n",
    "# Save the df\n",
    "\n",
    "result_df.to_csv(\"hugging-face-models-results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataset, create a table with results\n",
    "\n",
    "def results_table(result_df, datasets):\n",
    "    dataset_df = result_df[result_df[\"Test Dataset\"] == dataset]\n",
    "\n",
    "    # Sort values based on highes Macro F1\n",
    "    dataset_df = dataset_df.sort_values(by=\"Macro F1\", ascending=False)\n",
    "\n",
    "    # Round scores to 3 decimal places\n",
    "    dataset_df[\"Macro F1\"] = dataset_df[\"Macro F1\"].round(3)\n",
    "\n",
    "    dataset_df[\"Micro F1\"] = dataset_df[\"Micro F1\"].round(3)\n",
    "\n",
    "    print(dataset_df.to_markdown(index=False))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model           | Test Dataset     |   Macro F1 |   Micro F1 |   Epochs |   Learning Rate |\n",
      "|:----------------|:-----------------|-----------:|-----------:|---------:|----------------:|\n",
      "| bertic          | set.sr.plus.json |      0.618 |      0.954 |       10 |           4e-05 |\n",
      "| csebert         | set.sr.plus.json |      0.612 |      0.953 |        9 |           4e-05 |\n",
      "| xlm-r-base      | set.sr.plus.json |      0.604 |      0.953 |        6 |           4e-05 |\n",
      "| xlm-r-large     | set.sr.plus.json |      0.597 |      0.952 |       13 |           4e-05 |\n",
      "| xlm-r-bertic    | set.sr.plus.json |      0.59  |      0.953 |       13 |           4e-05 |\n",
      "| xlm-r-slobertic | set.sr.plus.json |      0.094 |      0.881 |       13 |           4e-05 |\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_df = results_table(result_df, datasets[0])\n",
    "\n",
    "type(current_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model           | Test Dataset   |   Macro F1 |   Micro F1 |   Epochs |   Learning Rate |\n",
      "|:----------------|:---------------|-----------:|-----------:|---------:|----------------:|\n",
      "| csebert         | hr500k.json    |      0.627 |      0.959 |        4 |           4e-05 |\n",
      "| bertic          | hr500k.json    |      0.596 |      0.957 |        9 |           4e-05 |\n",
      "| xlm-r-base      | hr500k.json    |      0.568 |      0.955 |        5 |           4e-05 |\n",
      "| xlm-r-slobertic | hr500k.json    |      0.158 |      0.922 |        7 |           4e-05 |\n",
      "| xlm-r-large     | hr500k.json    |      0.096 |      0.917 |        7 |           4e-05 |\n",
      "| xlm-r-bertic    | hr500k.json    |      0.096 |      0.917 |        7 |           4e-05 |\n",
      "\n",
      "\n",
      "| Model           | Test Dataset   |   Macro F1 |   Micro F1 |   Epochs |   Learning Rate |\n",
      "|:----------------|:---------------|-----------:|-----------:|---------:|----------------:|\n",
      "| csebert         | hr500k.json    |      0.627 |      0.959 |        4 |           4e-05 |\n",
      "| bertic          | hr500k.json    |      0.596 |      0.957 |        9 |           4e-05 |\n",
      "| xlm-r-base      | hr500k.json    |      0.568 |      0.955 |        5 |           4e-05 |\n",
      "| xlm-r-slobertic | hr500k.json    |      0.158 |      0.922 |        7 |           4e-05 |\n",
      "| xlm-r-large     | hr500k.json    |      0.096 |      0.917 |        7 |           4e-05 |\n",
      "| xlm-r-bertic    | hr500k.json    |      0.096 |      0.917 |        7 |           4e-05 |\n",
      "| Model           | Test Dataset             |   Macro F1 |   Micro F1 |   Epochs |   Learning Rate |\n",
      "|:----------------|:-------------------------|-----------:|-----------:|---------:|----------------:|\n",
      "| csebert         | reldi-normtagner-hr.json |      0.517 |      0.956 |        7 |           4e-05 |\n",
      "| bertic          | reldi-normtagner-hr.json |      0.495 |      0.961 |       10 |           4e-05 |\n",
      "| xlm-r-base      | reldi-normtagner-hr.json |      0.404 |      0.956 |        8 |           4e-05 |\n",
      "| xlm-r-large     | reldi-normtagner-hr.json |      0.096 |      0.918 |       11 |           4e-05 |\n",
      "| xlm-r-bertic    | reldi-normtagner-hr.json |      0.096 |      0.918 |       11 |           4e-05 |\n",
      "| xlm-r-slobertic | reldi-normtagner-hr.json |      0.096 |      0.918 |       11 |           4e-05 |\n",
      "\n",
      "\n",
      "| Model           | Test Dataset             |   Macro F1 |   Micro F1 |   Epochs |   Learning Rate |\n",
      "|:----------------|:-------------------------|-----------:|-----------:|---------:|----------------:|\n",
      "| csebert         | reldi-normtagner-hr.json |      0.517 |      0.956 |        7 |           4e-05 |\n",
      "| bertic          | reldi-normtagner-hr.json |      0.495 |      0.961 |       10 |           4e-05 |\n",
      "| xlm-r-base      | reldi-normtagner-hr.json |      0.404 |      0.956 |        8 |           4e-05 |\n",
      "| xlm-r-large     | reldi-normtagner-hr.json |      0.096 |      0.918 |       11 |           4e-05 |\n",
      "| xlm-r-bertic    | reldi-normtagner-hr.json |      0.096 |      0.918 |       11 |           4e-05 |\n",
      "| xlm-r-slobertic | reldi-normtagner-hr.json |      0.096 |      0.918 |       11 |           4e-05 |\n",
      "| Model           | Test Dataset             |   Macro F1 |   Micro F1 |   Epochs |   Learning Rate |\n",
      "|:----------------|:-------------------------|-----------:|-----------:|---------:|----------------:|\n",
      "| bertic          | reldi-normtagner-sr.json |      0.518 |      0.976 |       10 |           4e-05 |\n",
      "| csebert         | reldi-normtagner-sr.json |      0.512 |      0.973 |        7 |           4e-05 |\n",
      "| xlm-r-bertic    | reldi-normtagner-sr.json |      0.512 |      0.975 |       11 |           4e-05 |\n",
      "| xlm-r-base      | reldi-normtagner-sr.json |      0.491 |      0.972 |        8 |           4e-05 |\n",
      "| xlm-r-large     | reldi-normtagner-sr.json |      0.165 |      0.963 |       11 |           4e-05 |\n",
      "| xlm-r-slobertic | reldi-normtagner-sr.json |      0.097 |      0.949 |       11 |           4e-05 |\n",
      "\n",
      "\n",
      "| Model           | Test Dataset             |   Macro F1 |   Micro F1 |   Epochs |   Learning Rate |\n",
      "|:----------------|:-------------------------|-----------:|-----------:|---------:|----------------:|\n",
      "| bertic          | reldi-normtagner-sr.json |      0.518 |      0.976 |       10 |           4e-05 |\n",
      "| csebert         | reldi-normtagner-sr.json |      0.512 |      0.973 |        7 |           4e-05 |\n",
      "| xlm-r-bertic    | reldi-normtagner-sr.json |      0.512 |      0.975 |       11 |           4e-05 |\n",
      "| xlm-r-base      | reldi-normtagner-sr.json |      0.491 |      0.972 |        8 |           4e-05 |\n",
      "| xlm-r-large     | reldi-normtagner-sr.json |      0.165 |      0.963 |       11 |           4e-05 |\n",
      "| xlm-r-slobertic | reldi-normtagner-sr.json |      0.097 |      0.949 |       11 |           4e-05 |\n",
      "| Model           | Test Dataset     |   Macro F1 |   Micro F1 |   Epochs |   Learning Rate |\n",
      "|:----------------|:-----------------|-----------:|-----------:|---------:|----------------:|\n",
      "| bertic          | set.sr.plus.json |      0.618 |      0.954 |       10 |           4e-05 |\n",
      "| csebert         | set.sr.plus.json |      0.612 |      0.953 |        9 |           4e-05 |\n",
      "| xlm-r-base      | set.sr.plus.json |      0.604 |      0.953 |        6 |           4e-05 |\n",
      "| xlm-r-large     | set.sr.plus.json |      0.597 |      0.952 |       13 |           4e-05 |\n",
      "| xlm-r-bertic    | set.sr.plus.json |      0.59  |      0.953 |       13 |           4e-05 |\n",
      "| xlm-r-slobertic | set.sr.plus.json |      0.094 |      0.881 |       13 |           4e-05 |\n",
      "\n",
      "\n",
      "| Model           | Test Dataset     |   Macro F1 |   Micro F1 |   Epochs |   Learning Rate |\n",
      "|:----------------|:-----------------|-----------:|-----------:|---------:|----------------:|\n",
      "| bertic          | set.sr.plus.json |      0.618 |      0.954 |       10 |           4e-05 |\n",
      "| csebert         | set.sr.plus.json |      0.612 |      0.953 |        9 |           4e-05 |\n",
      "| xlm-r-base      | set.sr.plus.json |      0.604 |      0.953 |        6 |           4e-05 |\n",
      "| xlm-r-large     | set.sr.plus.json |      0.597 |      0.952 |       13 |           4e-05 |\n",
      "| xlm-r-bertic    | set.sr.plus.json |      0.59  |      0.953 |       13 |           4e-05 |\n",
      "| xlm-r-slobertic | set.sr.plus.json |      0.094 |      0.881 |       13 |           4e-05 |\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    current_df = results_table(result_df, datasets)\n",
    "    print(current_df.to_markdown(index=False))\n",
    "\n",
    "    # Save the table in markdown\n",
    "    with open(\"systems/hugging-face-models/results-{}.md\".format(dataset), \"w\") as result_file:\n",
    "        result_file.write(current_df.to_markdown(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
