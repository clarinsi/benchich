# BENCHić-lang - the language discrimination part of the BENCHić benchmark

The task in this part of the benchmark is to be able to discriminate between the four languages this benchmark covers - Bosnian, Croatian, Serbian and Montenegrin.

The benchmark consists of two datasets - a newspaper-based one covering Bosnian, Croatian and Serbian, and another Twitter-based one, covering all four languages.

## `char_ngram_baseline`

This part covers the in- and cross-domain baselines, performed with character-3-gram tokenizer and a SVM classifier. Running
```python
python char_ngram_baseline.py 
```
performs the baseline experiments, outputs classification reports of different settings to stdout and saves predictions to `char_ngram_baseline.predictions.json`.

## `web`

This part covers the classifier, trained on web data: first the vocabulary gets extracted from web data, only 100 most significant words per language pair are propagated to the CountVectorizer tokenizer. This tokenizer and a different part of web data are then trained together and evaluated on Twitter and SETimes data. Run
```python
python web.py
```
to perform the training and evaluation on SETimes, Twitter 3 (hr, bs, sr) and Twitter 4 (hr, bs, sr, me) data. The classification reports are output to stdout and predictions are saved in a json file in baseline-compatible format. 

Note that the web data is not included in this repository.

## `data`

This directory contains the data to be used for training and evaluation of the classifiers.

### SETimes
News articles in hr, bs, and sr.
### Twitter
Twitter data in hr, bs, sr, and me.

Do not insert data below this line!
# Autogenerated comparison of results on different test sets:
## Test data: setimes
|    | system               | train     | test    |   macroF1 |   microF1 |
|---:|:---------------------|:----------|:--------|----------:|----------:|
|  0 | char_ngram_baseline  | setimes   | setimes |  0.994634 |  0.994571 |
|  1 | web+NaiveBayes       | web3class | setimes |  0.956932 |  0.956569 |
|  2 | clean-char-6gram-web | web       | setimes |  0.842259 |  0.84582  |
|  3 | char_ngram_baseline  | twitter3  | setimes |  0.74733  |  0.742671 |
## Test data: twitter3
|    | system               | train     | test     |   macroF1 |   microF1 |
|---:|:---------------------|:----------|:---------|----------:|----------:|
|  0 | clean-char-6gram-web | web       | twitter3 |  0.986409 |  0.991071 |
|  1 | web+NaiveBayes       | web3class | twitter3 |  0.896819 |  0.946429 |
|  2 | char_ngram_baseline  | twitter3  | twitter3 |  0.87471  |  0.928571 |
|  3 | char_ngram_baseline  | setimes   | twitter3 |  0.672202 |  0.839286 |
## Test data: twitter
|    | system               | train     | test    |   macroF1 |   microF1 |
|---:|:---------------------|:----------|:--------|----------:|----------:|
|  0 | char_ngram_baseline  | twitter   | twitter |  0.731548 |  0.869919 |
|  1 | clean-char-6gram-web | web       | twitter |  0.726197 |  0.910569 |
|  2 | web+NaiveBayes       | web4class | twitter |  0.681937 |  0.869919 |
